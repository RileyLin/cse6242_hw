# Q3 Quick Reference Card

## ğŸ“‹ **Essential Info**

**Your GT Username:** `wlin99`  
**Your S3 Bucket:** `cse6242-wlin99`  
**Data Source:** `s3://cse6242-hw3-q3` (pre-provided)  
**AWS Region:** `us-east-1` (recommended)

---

## ğŸš€ **Quick Start (5 Steps)**

### 1ï¸âƒ£ Create S3 Bucket
```
Name: cse6242-wlin99
Region: us-east-1
Settings: Default (block public access)
```

### 2ï¸âƒ£ Create EMR Cluster
```
Release: emr-7.x
Apps: Spark + JupyterEnterpriseGateway
Instances: 3 Ã— m5.xlarge
Wait: ~10-15 min until "Waiting" status
```

### 3ï¸âƒ£ Upload Notebook
```
EMR Console â†’ Notebooks â†’ Create notebook
Name: q3
Upload: q3.ipynb from local folder
```

### 4ï¸âƒ£ Run Large Dataset
```python
main('large', 's3://cse6242-wlin99')
```
Wait ~10-30 minutes

### 5ï¸âƒ£ Download & Submit
```
S3 â†’ cse6242-wlin99 â†’ output_large/ â†’ download CSV
Rename to: q3_output_large.csv
Submit: q3.ipynb + q3_output_large.csv
```

---

## âš ï¸ **CRITICAL: Terminate Cluster When Done!**
```
EMR Console â†’ Select cluster â†’ Terminate
Cost: ~$0.79/hour if running!
```

---

## ğŸ“ **Files Created**

| File | Description |
|------|-------------|
| `q3.ipynb` | âœ… All 6 functions implemented |
| `Q3_IMPLEMENTATION_SUMMARY.md` | Detailed code explanations |
| `AWS_SETUP_GUIDE.md` | Step-by-step AWS instructions |
| `QUICK_REFERENCE.md` | This cheat sheet |

---

## âœ… **What's Implemented**

1. âœ… `user()` â†’ Returns 'wlin99'
2. âœ… `trip_statistics()` â†’ Describes trip_distance
3. âœ… `busiest_hour()` â†’ Hour with most trips
4. âœ… `most_freq_pickup_locations()` â†’ Top 10 pickup locations
5. âœ… `avg_trip_distance_and_duration()` â†’ Averages by hour (24 rows)
6. âœ… `most_freq_peak_hour_fares()` â†’ Top 10 peak hour routes with zone names

---

## ğŸ§ª **Testing Commands**

```python
# Load small data
trips, zones = load_data('small')

# Test each function
user()  # Returns 'wlin99'
trip_statistics(trips).show()
busiest_hour(trips).show()
most_freq_pickup_locations(trips).show()
avg_trip_distance_and_duration(trips).show(24)
most_freq_peak_hour_fares(trips, zones).show()

# Run full pipeline on large
main('large', 's3://cse6242-wlin99')
```

---

## ğŸ’° **Cost Estimate**

- **S3:** <$0.10 (pennies)
- **EMR:** ~$0.79/hour
- **Total:** $2-3 (if efficient)
- **If left running overnight:** $19+ ğŸ’¸

---

## ğŸ“¤ **Submission Checklist**

- [ ] `q3.ipynb` (notebook with all functions)
- [ ] `q3_output_large.csv` (10 rows + header)
- [ ] Verified CSV has correct columns
- [ ] EMR cluster terminated

---

## ğŸ†˜ **Quick Troubleshooting**

| Problem | Solution |
|---------|----------|
| Cluster won't start | Try m4.xlarge or different region |
| Access Denied to S3 | Check IAM roles, bucket name |
| Code runs forever | Check cluster status, look at Spark UI |
| Out of memory | Increase to m5.2xlarge |
| Can't download CSV | Check S3 â†’ output_large/ folder |

---

## ğŸ“ **Support**

- **AWS Setup:** Read `AWS_SETUP_GUIDE.md`
- **Code Details:** Read `Q3_IMPLEMENTATION_SUMMARY.md`
- **AWS Console:** https://console.aws.amazon.com/
- **S3 Console:** https://s3.console.aws.amazon.com/
- **EMR Console:** https://console.aws.amazon.com/emr/

---

**Remember: TERMINATE YOUR CLUSTER when done! âš ï¸**

